{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with Kalman Filters and AR\n",
    "\n",
    "Take the predicted state from process space of what comes out of model and use it in predictions  \n",
    "\n",
    "Assume measurements are poor, model that by having random noise on measurements  \n",
    "\n",
    "Assume we have a perfect model and assume need to change measurements  \n",
    "Gonna operate on the lags of   \n",
    "Parameters won't change  \n",
    "\n",
    "**Take what comes out of the Kalman Gain Model => turn into an observation => use it to do predictions with AR**\n",
    "\n",
    "In the ```kalman_step``` function we now return the predicted observation as well as the state estimate and state covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def kalman_step (F,Q,R,state_covariance,H, state_estimate,observation):\n",
    "\n",
    "    predicted_state = F @ state_estimate\n",
    "    predicted_covariance = F @ state_covariance @ F.T + Q\n",
    "    \n",
    "    predicted_observation = H @ predicted_state # new addition\n",
    "    \n",
    "    prefit_residual = observation - H @ predicted_state\n",
    "    prefit_covariance = H @ predicted_covariance @ H.T + R\n",
    "    kalman_gain = (predicted_covariance @ np.transpose(H)) @ np.linalg.inv(prefit_covariance)\n",
    "    state_estimate = predicted_state + kalman_gain @ prefit_residual\n",
    "    state_covariance = (np.identity(len(state_estimate)) - kalman_gain @ H) @ state_covariance\n",
    "\n",
    "    # return predicted_observation as well\n",
    "    return (predicted_observation, state_estimate,   state_covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes in the ```kalman_multi``` function  \n",
    "- add in predictions = []\n",
    "- in loop append new predicted observations to array\n",
    "- return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_multi (F,Q,R,state_covariance,H, state_estimate, observations):\n",
    "    predictions = [] ##\n",
    "    for i in range (len(observations)):\n",
    "        (predicted_observation, state_estimate, state_covariance) = kalman_step(F,Q,R,state_covariance,H, state_estimate, observations[i])\n",
    "        predictions.append(predicted_observation) ##\n",
    "        # print(' state after :', i, 'is',  state_estimate)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tesla Example\n",
    "now adding some random noise to it with:  \n",
    " ``` series = tsla + 0.1 * np.random.randn(len(tsla)) ```\n",
    "\n",
    "Idea is that we have noisy measurements of the prices, trying to get from these noisy readings back to better more accurate obseravtions of the prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance\n",
    "import statsmodels.api as sm\n",
    "\n",
    "tsla = np.log(yfinance.Ticker('TSLA').history(start='2015-01-01', end='2022-01-01', interval='1d').reset_index()['Close'])\n",
    "\n",
    "series = tsla + 0.1 * np.random.randn(len(tsla))\n",
    "\n",
    "ar_deg = 3\n",
    "\n",
    "model = sm.tsa.AutoReg(series, lags = ar_deg, trend='n').fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AR(3): states  \n",
    "A state will be a vector of lags. Length will be the order (3)  \n",
    "``` state_estimate = np.array(series[ar_deg-1::-1]) ``` \n",
    "will return ``` [a3, a2, a1] ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.63462577 3.61893205 3.77032727]\n"
     ]
    }
   ],
   "source": [
    "state_estimate = np.array(series[ar_deg-1::-1])\n",
    "print(state_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AR(3): state transition\n",
    "Gives a matrix the first row of which is the AR paramaters\n",
    "- dot that with last three lags to get prediction for next state  \n",
    "\n",
    "Second row is [1 0 0 ...] \n",
    "- used to be the first lag is now the second  \n",
    "\n",
    "In general get the paramaters on top and rest are shifting one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38935111, 0.29965924, 0.31172904],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = np.vstack([model.params, np.hstack([np.identity(ar_deg - 1), np.zeros((ar_deg - 1, 1))])])\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise\n",
    "Process noise gives a 1 (the model_cov) on the top row and the others all zeros.  \n",
    "Be uncertainty for the AR paramater multiplication but not for the shifts  \n",
    "\n",
    "Measurement Noise is a singleton, just 1 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "model_cov = 1.0\n",
    "\n",
    "# Process Noise\n",
    "Q = np.diag([model_cov] + [0.]*(ar_deg - 1))\n",
    "\n",
    "observation_cov = 1.0\n",
    "\n",
    "# Measurement Noise\n",
    "R = np.array(observation_cov)\n",
    "\n",
    "print(Q,'\\n', R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```H = [1 0 0 0 ...]``` because to get from series of lags to a price just take top one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = np.array([[1] + [0.] * (ar_deg - 1)])\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_covariance = np.zeros((ar_deg, ar_deg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.87789977, 3.6520388 , 3.62414825, ..., 7.06488899, 6.99123073,\n",
       "       7.13525668])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = np.array(series)[ar_deg: ]\n",
    "# ignore the first ar_deg amount in the series\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([3.6749125]), array([3.68762332]), array([3.69350618])] [nan, nan, nan, 3.674912496624447, 3.687623320746377, 3.6935061822298594]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# predicted_observations = kalman_multi(F, Q, R, state_covariance, H, state_estimate, observations)\n",
    "predicted_observations = kalman_multi(F,Q,R,state_covariance,H,state_estimate, observations)\n",
    "\n",
    "# create predicted values array with ar_deg nan to start series off\n",
    "predicted_values = [math.nan] * ar_deg\n",
    "\n",
    "# add predicted observations to predicted values\n",
    "for state in predicted_observations: \n",
    "    predicted_values.append(state[0])\n",
    "\n",
    "print(predicted_observations[:3], predicted_values[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare RMSE of models\n",
    "1st model is the KF with AR\n",
    "\n",
    "Changed the series but have not changed the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11983011548369023"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rmse(predicted, actual):\n",
    "    # print(predicted, actual)1\n",
    "    diffs = predicted - actual\n",
    "    # print(diffs)\n",
    "    return math.sqrt(np.mean(diffs ** 2))\n",
    "\n",
    "rmse(np.concatenate(predicted_observations), series[ar_deg:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model is the straight AR(3) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1219359817318891"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rmse(model.predict(), series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AR with Kalman Filters Pt. 2\n",
    "\n",
    "[Lecture Video](https://learn.london.ac.uk/mod/page/view.php?id=80173&forceview=1)\n",
    "No slides for this lecture so some missed stuff might be in video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea behind above example is we some parameters and have perturbed measurements. \n",
    "Going to keep the paramaters but change the measurements.  \n",
    "\n",
    "Here doing the opposite. Change the parameters and keep measurements even though they are still perturbed by noise.  \n",
    "\n",
    "Similar in spirit to an ARMA with p=1 \n",
    "\n",
    "Different setup:\n",
    "- assume we have the readings and going to adapt the model parameters\n",
    "- much more like we are used to doing\n",
    "- In Kalman filter terms, a state is a vector of parameters\n",
    "- H doing a lot of work, moves us from the parameters to the observable space (price) using dot product\n",
    "\n",
    "In KF terms:\n",
    "1. States are the parameters\n",
    "2. Prediction stage, we won't change the state => F = Identity Matrix\n",
    "- state is ``` [alpha1, alpha2, alpha3, alpha4] ```\n",
    "- F is not not doing much, just identity matrix\n",
    "- Q is zeros. Q normally the noise that comes with the F matrix which isn't doing anything Expect noise in the identity computation  \n",
    "- Real action is in H\n",
    "\n",
    "H\n",
    "- H is transformation that takes you from states to observables\n",
    "- State is the paramaters. Observable = share price\n",
    "- What do we need to multipyly the parameters by to get a share price?\n",
    "    - LAGS\n",
    "H will be 4 lags. It will be a different vector of lags for each prediction.  \n",
    "The H's will change with each step  \n",
    "\n",
    "To implement - need to change the multi-step code  \n",
    "- instead of taking a static H as input, take an array that we call Hs  \n",
    "- array will have a vector of 4 lags at each position  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_step_2 (F,Q,R,state_covariance,H, state_estimate,observation):\n",
    "\n",
    "    predicted_state = F @ state_estimate\n",
    "    predicted_covariance = F @ state_covariance @ F.T + Q\n",
    "    \n",
    "    predicted_observation = H @ predicted_state # new addition\n",
    "    \n",
    "    prefit_residual = observation - H @ predicted_state\n",
    "    prefit_covariance = H @ predicted_covariance @ H.T + R\n",
    "\n",
    "    kalman_gain = (predicted_covariance @ np.transpose(H)) @ np.linalg.inv(prefit_covariance)\n",
    "    \n",
    "    state_estimate = predicted_state + kalman_gain @ prefit_residual\n",
    "    state_covariance = (np.identity(len(state_estimate)) - kalman_gain @ H) @ state_covariance\n",
    "\n",
    "    # return predicted_observation as well\n",
    "    return (predicted_observation, state_estimate,   state_covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman_multi_2 (F,Q,R,state_covariance, Hs, state_estimate, observations):\n",
    "    predictions = [] ##\n",
    "    for i in range (len(observations)):\n",
    "        (predicted_observation, state_estimate, state_covariance) = kalman_step(F,Q,R,state_covariance, Hs[i], state_estimate, observations[i])\n",
    "        predictions.append(predicted_observation) ##\n",
    "        # print(' state after :', i, 'is',  state_estimate)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12034237700866157"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_deg = 4\n",
    "\n",
    "model2 = sm.tsa.AutoReg(series, lags=ar_deg, trend='n').fit()\n",
    "\n",
    "rmse(model2.predict(), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.identity(ar_deg)\n",
    "Q = np.zeros((ar_deg, ar_deg))\n",
    "observation_cov = 1.0\n",
    "R = np.array ([[observation_cov]])\n",
    "state_covariance = np.identity(ar_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hs = []\n",
    "for i in range (len(series) - ar_deg):\n",
    "    Hs.append(np.array([series[i : i + ar_deg]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_estimate = np.array([0] * (ar_deg - 1) + [1])\n",
    "\n",
    "predicted_observations = kalman_multi_2(F, Q, R, state_covariance, Hs, state_estimate, np.array(series[ar_deg:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs shown in [lecture video](https://learn.london.ac.uk/mod/page/view.php?id=80173&forceview=1) at time 19:00 and 19:15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fc6efb3340bf4aae142c4471c3414bb5b17e6e80ba42a259676c40f0503db89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
